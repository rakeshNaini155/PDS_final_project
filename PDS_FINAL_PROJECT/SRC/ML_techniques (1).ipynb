{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "logestic regression algorithm"
      ],
      "metadata": {
        "id": "C9NBKj2zNge7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "â€‹"
      ],
      "metadata": {
        "id": "k4GJ4Y8WIIhQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4pGNH5wNAVx",
        "outputId": "4441249d-6db1-4392-dd7b-ffb833a43472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9246119733924612\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.93      0.99      0.96       382\n",
            "        True       0.91      0.57      0.70        69\n",
            "\n",
            "    accuracy                           0.92       451\n",
            "   macro avg       0.92      0.78      0.83       451\n",
            "weighted avg       0.92      0.92      0.92       451\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('/content/DataAnalyst.csv')\n",
        "\n",
        "# Data Cleaning and Preprocessing\n",
        "# (Assuming that the dataset includes columns like 'Job Title', 'Job Description', 'Location', 'Rating', etc.)\n",
        "\n",
        "# Step 1: Identify various Big Data job families in the given dataset\n",
        "job_descriptions = dataset[\"Job Description\"].tolist()\n",
        "big_data_skills = [\"big data\", \"hadoop\", \"spark\", \"impala\", \"cassandra\", \"kafka\", \"hdfs\", \"hbase\", \"hive\", \"mongo db\", 'flume', 'sqoop', 'flink']\n",
        "\n",
        "big_data_required = defaultdict(int)\n",
        "\n",
        "for skill in big_data_skills:\n",
        "    for description in job_descriptions:\n",
        "        if skill in description.lower():\n",
        "            big_data_required[skill] += 1\n",
        "\n",
        "# Create a DataFrame for Big Data job families\n",
        "big_data_df = pd.DataFrame(list(big_data_required.items()), columns=['Big Data Technologies', 'Skills Requirement'])\n",
        "big_data_df.sort_values(['Skills Requirement'], axis=0, ascending=False, inplace=True)\n",
        "\n",
        "dataset['BigDataSkill'] = dataset['Job Description'].apply(lambda x: any(skill in x.lower() for skill in big_data_skills))\n",
        "\n",
        "# Feature Engineering\n",
        "X = dataset['Job Description']\n",
        "y = dataset['BigDataSkill']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Build a logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test_vec)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random forest algorithm"
      ],
      "metadata": {
        "id": "jcmATELEN5dL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('/content/DataAnalyst.csv')\n",
        "\n",
        "# Data Cleaning and Preprocessing\n",
        "# (Assuming that the dataset includes columns like 'Job Title', 'Job Description', 'Location', 'Rating', etc.)\n",
        "\n",
        "# Step 1: Identify various Big Data job families in the given dataset\n",
        "job_descriptions = dataset[\"Job Description\"].tolist()\n",
        "big_data_skills = [\"big data\", \"hadoop\", \"spark\", \"impala\", \"cassandra\", \"kafka\", \"hdfs\", \"hbase\", \"hive\", \"mongo db\", 'flume', 'sqoop', 'flink']\n",
        "\n",
        "big_data_required = defaultdict(int)\n",
        "\n",
        "for skill in big_data_skills:\n",
        "    for description in job_descriptions:\n",
        "        if skill in description.lower():\n",
        "            big_data_required[skill] += 1\n",
        "\n",
        "# Create a DataFrame for Big Data job families\n",
        "big_data_df = pd.DataFrame(list(big_data_required.items()), columns=['Big Data Technologies', 'Skills Requirement'])\n",
        "big_data_df.sort_values(['Skills Requirement'], axis=0, ascending=False, inplace=True)\n",
        "\n",
        "dataset['BigDataSkill'] = dataset['Job Description'].apply(lambda x: any(skill in x.lower() for skill in big_data_skills))\n",
        "\n",
        "# Feature Engineering\n",
        "X = dataset['Job Description']\n",
        "y = dataset['BigDataSkill']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Build a Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_rf = rf_model.predict(X_test_vec)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slaC1IDsNmp6",
        "outputId": "b40260a4-1940-439c-9598-d1b71b11d441"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.917960088691796\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.91      1.00      0.95       382\n",
            "        True       1.00      0.46      0.63        69\n",
            "\n",
            "    accuracy                           0.92       451\n",
            "   macro avg       0.96      0.73      0.79       451\n",
            "weighted avg       0.93      0.92      0.90       451\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision tree"
      ],
      "metadata": {
        "id": "jKemMrDUOTvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('/content/DataAnalyst.csv')\n",
        "\n",
        "# Data Cleaning and Preprocessing\n",
        "# (Assuming that the dataset includes columns like 'Job Title', 'Job Description', 'Location', 'Rating', etc.)\n",
        "\n",
        "# Step 1: Identify various Big Data job families in the given dataset\n",
        "job_descriptions = dataset[\"Job Description\"].tolist()\n",
        "big_data_skills = [\"big data\", \"hadoop\", \"spark\", \"impala\", \"cassandra\", \"kafka\", \"hdfs\", \"hbase\", \"hive\", \"mongo db\", 'flume', 'sqoop', 'flink']\n",
        "\n",
        "big_data_required = defaultdict(int)\n",
        "\n",
        "for skill in big_data_skills:\n",
        "    for description in job_descriptions:\n",
        "        if skill in description.lower():\n",
        "            big_data_required[skill] += 1\n",
        "\n",
        "# Create a DataFrame for Big Data job families\n",
        "big_data_df = pd.DataFrame(list(big_data_required.items()), columns=['Big Data Technologies', 'Skills Requirement'])\n",
        "big_data_df.sort_values(['Skills Requirement'], axis=0, ascending=False, inplace=True)\n",
        "\n",
        "dataset['BigDataSkill'] = dataset['Job Description'].apply(lambda x: any(skill in x.lower() for skill in big_data_skills))\n",
        "\n",
        "# Feature Engineering\n",
        "X = dataset['Job Description']\n",
        "y = dataset['BigDataSkill']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "\n",
        "# Build a Decision Tree model\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_dt = dt_model.predict(X_test_vec)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOdy8JkTOYMD",
        "outputId": "abe1ad0c-4971-46ac-81d1-6ee05b437e0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9711751662971175\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.98      0.99      0.98       382\n",
            "        True       0.94      0.87      0.90        69\n",
            "\n",
            "    accuracy                           0.97       451\n",
            "   macro avg       0.96      0.93      0.94       451\n",
            "weighted avg       0.97      0.97      0.97       451\n",
            "\n"
          ]
        }
      ]
    }
  ]
}